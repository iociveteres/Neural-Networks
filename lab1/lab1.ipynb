{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0c984529",
      "metadata": {
        "id": "0c984529"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "95b5ef68",
      "metadata": {},
      "outputs": [],
      "source": [
        "# def __init__(self, root, resize, mode):\n",
        "#         super(Pokemon, self).__init__()\n",
        "\n",
        "#         self.root = root\n",
        "#         self.resize = resize\n",
        "\n",
        "#         self.name2label = {}\n",
        "#         for name in sorted(os.listdir(os.path.join(root))):\n",
        "#             if not os.path.isdir(os.path.join(root, name)):\n",
        "#                 continue\n",
        "#            # len(..) returns from 0 - n based on saved labels so far\n",
        "#             self.name2label[name] = len(self.name2label.keys())\n",
        "\n",
        "#         print(self.name2label)\n",
        "\n",
        "#         # image, label, helper function load_csv()\n",
        "#         self.images, self.labels = self.load_csv('images.csv')\n",
        "\n",
        "#         if mode == 'train':  # 60%\n",
        "#             self.images = self.images[:int(0.6 * len(self.images))]\n",
        "#             self.labels = self.labels[:int(0.6 * len(self.labels))]\n",
        "\n",
        "#         elif mode == 'val':  # 20% (60-80%)\n",
        "#             self.images = self.images[int(0.6 * len(self.images)):int(0.8 * len(self.images))]\n",
        "#             self.labels = self.labels[int(0.6 * len(self.labels)):int(0.8 * len(self.labels))]\n",
        "\n",
        "#         elif mode == 'test':  # 20% (80-100%)\n",
        "#             self.images = self.images[int(0.8 * len(self.images)):]\n",
        "#             self.labels = self.labels[int(0.8 * len(self.labels)):]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9fcfb810",
      "metadata": {},
      "outputs": [],
      "source": [
        "# def __getitem__(self, idx):\n",
        "#         # idx: [0:len(images)]\n",
        "#         # self.images, self.labels\n",
        "#         # img: 'pokemon\\\\bulbasaur\\\\00000000.png'\n",
        "#         # label: 0\n",
        "#         img, label = self.images[idx], self.labels[idx]\n",
        "\n",
        "#         # tf = transforms.Compose([\n",
        "#         #     lambda x: Image.open(x).convert('RGB'),  # str path -> img data\n",
        "#         #     transforms.Resize((int(self.resize * 1.25), int(self.resize * 1.25))),\n",
        "#         #     transforms.RandomRotation(15),\n",
        "#         #     transforms.CenterCrop(self.resize),\n",
        "#         #     transforms.ToTensor(),\n",
        "#         #     transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "#         #                          std=[0.229, 0.224, 0.225])  # from imagenet\n",
        "#         # ])\n",
        "\n",
        "#         img = tf(img)\n",
        "#         label = torch.tensor(label)\n",
        "\n",
        "#         return img, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c6b6ab7",
      "metadata": {},
      "outputs": [],
      "source": [
        "# def __len__(self):\n",
        "#         return len(self.images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7bd7b67a",
      "metadata": {},
      "outputs": [],
      "source": [
        "tf = transforms.Compose([\n",
        "    transforms.Resize(128),\n",
        "    transforms.CenterCrop(128),\n",
        "    transforms.RandomAffine(degrees=90),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225] )\n",
        "    ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b283ea0c",
      "metadata": {},
      "outputs": [],
      "source": [
        "db = torchvision.datasets.ImageFolder(root='cats', transform=tf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f660723",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(db.class_to_idx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a6f5b4ac",
      "metadata": {},
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "loader = torch.utils.data.DataLoader(db, batch_size=batch_size, shuffle=True, num_workers=6)\n",
        "classes = ('lastik', 'other')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a5edf19d",
      "metadata": {},
      "outputs": [],
      "source": [
        "train_set, test_set = torch.utils.data.random_split(db, [0.7, 0.3], generator=torch.Generator().manual_seed(42))\n",
        "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=6)\n",
        "test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size, shuffle=True, num_workers=6)\n",
        "test_len = print(len(test_set))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f1f70e00",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104,
          "referenced_widgets": [
            "5aeea86d346c49a9a070efeb746c15c3",
            "fcdd0995425442de83aedc6c157396f9",
            "13db09b7d5f24cbc82eb6bb4a7e2b04d",
            "eda4571c6119464896cda99e85841e46",
            "cf94e662f9114e6eac24ccc6b671efad",
            "29acf99c6faf488d9e6b7492ead45986",
            "2f636d53c03440a6a47b2dafcfd8886f",
            "fe780edc9b174e5a8fb91a6272b4ecc1",
            "5b92f21e071d4887bd491b55dc3c09e4",
            "006b68923f6c4ed6abf97a717eae68ab",
            "c967b526ebda48fb98be888e61843fc9"
          ]
        },
        "id": "f1f70e00",
        "outputId": "8b931ac0-f11a-449f-cc8f-1f8348624e4d"
      },
      "outputs": [],
      "source": [
        "# transform = transforms.Compose(\n",
        "#     [transforms.ToTensor(),\n",
        "#      transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "\n",
        "# train_set = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "#                                         download=True, transform=transform)\n",
        "# trainloader = torch.utils.data.DataLoader(train_set, batch_size=batch_size,\n",
        "#                                           shuffle=True, num_workers=2)\n",
        "\n",
        "# test_set = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "#                                        download=True, transform=transform)\n",
        "# testloader = torch.utils.data.DataLoader(test_set, batch_size=batch_size,\n",
        "#                                          shuffle=False, num_workers=2)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0284914c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "id": "0284914c",
        "outputId": "bc2feea3-177b-437e-da09-c89f274cf6ac"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# функция для показа изображения\n",
        "def imshow(img):\n",
        "    img = img  / 2  + 0.5    \n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# получаем несколько случайных обучающих изображений\n",
        "dataiter = iter(train_loader)\n",
        "images, labels = next(dataiter)\n",
        "\n",
        "# показать изображения\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "# показать лейблы изображений\n",
        "print(' '.join(f'{classes[labels[j]]:5s}' for j in range(batch_size)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2bc5eeec",
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch import flatten"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8c968811",
      "metadata": {},
      "outputs": [],
      "source": [
        "numChannels = 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b09850a1",
      "metadata": {
        "id": "b09850a1"
      },
      "outputs": [],
      "source": [
        "# Инициализация модели\n",
        "class Net_1(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5) # (in_channels, out_channels, kernel_size) Применяет 2D-свертку к входному сигналу, состоящему из нескольких входных плоскостей.\n",
        "        self.pool = nn.MaxPool2d(2, 2) # (kernel_size, stride) Применяет MaxPool2D-объединение к входному сигналу, состоящему из нескольких входных плоскостей.\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5) \n",
        "        self.fc1 = nn.Linear(13456, 120)# (in_features , out_features) Применяет линейное преобразование к входящим данным\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 2)\n",
        "\n",
        "    # Это forward функция, которая определяет структуру сети.\n",
        "    # Здесь мы принимаем только один вход, но можно использовать больше.\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = torch.flatten(x, 1) #(input, start_dim) Сглаживает input путем преобразования его в одномерный тензор.\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aa934f1d",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Инициализация модели\n",
        "class Net_2(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 10, kernel_size=(5, 5)) # (in_channels, out_channels, kernel_size) Применяет 2D-свертку к входному сигналу, состоящему из нескольких входных плоскостей.\n",
        "        self.pool = nn.MaxPool2d(2, 2) # (kernel_size, stride) Применяет MaxPool2D-объединение к входному сигналу, состоящему из нескольких входных плоскостей.\n",
        "        self.conv2 = nn.Conv2d(10, 30, 5) \n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.fc1 = nn.Linear(25230, 500)# (in_features , out_features) Применяет линейное преобразование к входящим данным\n",
        "        self.fc2 = nn.Linear(500, 2)\n",
        "\n",
        "    # Это forward функция, которая определяет структуру сети.\n",
        "    # Здесь мы принимаем только один вход, но можно использовать больше.\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = torch.flatten(x, 1) #(input, start_dim) Сглаживает input путем преобразования его в одномерный тензор.\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "84dda47e",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Инициализация модели\n",
        "class Net_3(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 10, 5) # (in_channels, out_channels, kernel_size) Применяет 2D-свертку к входному сигналу, состоящему из нескольких входных плоскостей.\n",
        "        self.pool = nn.MaxPool2d(2, 2) # (kernel_size, stride) Применяет MaxPool2D-объединение к входному сигналу, состоящему из нескольких входных плоскостей.\n",
        "        self.conv2 = nn.Conv2d(10, 20, 5) \n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv3 = nn.Conv2d(20, 30, 5) \n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.fc1 = nn.Linear(4320, 120)# (in_features , out_features) Применяет линейное преобразование к входящим данным\n",
        "        self.fc2 = nn.Linear(120, 80)\n",
        "        self.fc3 = nn.Linear(80, 2)\n",
        "\n",
        "    # Это forward функция, которая определяет структуру сети.\n",
        "    # Здесь мы принимаем только один вход, но можно использовать больше.\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = self.pool(F.relu(self.conv3(x)))\n",
        "        x = torch.flatten(x, 1) #(input, start_dim) Сглаживает input путем преобразования его в одномерный тензор.\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "98bd64e0",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Инициализация модели\n",
        "class Net_4(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 10, 5) # (in_channels, out_channels, kernel_size) Применяет 2D-свертку к входному сигналу, состоящему из нескольких входных плоскостей.\n",
        "        self.pool = nn.MaxPool2d(2, 2) # (kernel_size, stride) Применяет MaxPool2D-объединение к входному сигналу, состоящему из нескольких входных плоскостей.\n",
        "        self.fc1 = nn.Linear(38440, 500)# (in_features , out_features) Применяет линейное преобразование к входящим данным\n",
        "        self.fc2 = nn.Linear(500, 200)\n",
        "        self.fc3 = nn.Linear(200, 100)\n",
        "        self.fc4 = nn.Linear(100, 2)\n",
        "\n",
        "    # Это forward функция, которая определяет структуру сети.\n",
        "    # Здесь мы принимаем только один вход, но можно использовать больше.\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = torch.flatten(x, 1) #(input, start_dim) Сглаживает input путем преобразования его в одномерный тензор.\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = F.relu(self.fc3(x))\n",
        "        x = self.fc4(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b70ac42",
      "metadata": {},
      "outputs": [],
      "source": [
        "nets = [] \n",
        "nets.append(Net_1())\n",
        "nets.append(Net_2())\n",
        "nets.append(Net_3())\n",
        "nets.append(Net_4())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "SBQW3zETNF1Z",
      "metadata": {
        "id": "SBQW3zETNF1Z"
      },
      "source": [
        "Коэффициент скорости обучения – это гиперпараметр, определяющий порядок того, как мы будем корректировать наши весы с учётом функции потерь в градиентном спуске. Чем ниже величина, тем медленнее мы движемся по наклонной. Хотя при использовании низкого коэффициента скорости обучения мы можем получить положительный эффект в том смысле, чтобы не пропустить ни одного локального минимума, — это также может означать, что нам придётся затратить много времени на cходимость, особенно если мы попали в область плато.\n",
        "\n",
        "Импульс (momentum) в нейронных сетях — это вариант стохастического градиентного спуска . Он заменяет градиент импульсом , который представляет собой совокупность градиентов, как очень хорошо объяснено [здесь](https://towardsdatascience.com/10-gradient-descent-optimisation-algorithms-86989510b5e9).\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4a2d538d",
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_n_params(model):\n",
        "    pp=0\n",
        "    for p in list(model.parameters()):\n",
        "        nn=1\n",
        "        for s in list(p.size()):\n",
        "            nn = nn*s\n",
        "        pp += nn\n",
        "    return pp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a2ca8923",
      "metadata": {
        "id": "a2ca8923"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "# Критерии полезны для обучения нейронной сети. Учитывая входные данные и цель, они вычисляют градиент в соответствии с заданной функцией потерь\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# torch.optim - это пакет, реализующий различные алгоритмы оптимизации. Наиболее часто используемые методы уже поддерживаются, \n",
        "# а интерфейс достаточно общий, так что более сложные методы могут быть также легко интегрированы в будущем."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d6eb9589",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d6eb9589",
        "outputId": "30438c88-b6ac-45ec-a0a4-e9fa472b2c78"
      },
      "outputs": [],
      "source": [
        "for i, net in enumerate(nets):\n",
        "    print(f'---- net {i} ----')\n",
        "    print(type(net))\n",
        "    optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "    for epoch in range(2):  # многократное прохождение по набору данных\n",
        "        running_loss = 0.0\n",
        "        for i, data in enumerate(train_loader, 0):\n",
        "            # получаем входные данные; данные - это список [inputs, labels].\n",
        "            inputs, labels = data\n",
        "\n",
        "            # обнуляем градиенты параметров\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # forward + backward + optimize\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # вывести статистику обучения\n",
        "            running_loss += loss.item()\n",
        "            if i % 10 == 9:    # вывести каждые 300 mini-batches\n",
        "                print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 10:.3f}')\n",
        "                running_loss = 0.0\n",
        "    print('Finished Training')\n",
        "\n",
        "    #Сохранение нашей модели\n",
        "    PATH = './cats_net_'+ str(i) +'.pth'\n",
        "    torch.save(net.state_dict(), PATH)\n",
        "\n",
        "    dataiter = iter(test_loader)\n",
        "    images, labels = next(dataiter)\n",
        "    outputs = net(images)\n",
        "\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    # поскольку мы не обучаемся, нам не нужно вычислять градиенты для наших выходов\n",
        "    with torch.no_grad():\n",
        "        for data in test_loader:\n",
        "            images, labels = data\n",
        "            # рассчитываем выходные данные, пропуская изображения через сеть\n",
        "            outputs = net(images)\n",
        "            # класс с наибольшей мощностью - это то, что мы выбираем в качестве предсказания\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print(f'Accuracy of the network on the {test_len} test images: {100 * correct // total} %')\n",
        "\n",
        "    # Подготовка\n",
        "    correct_pred = {classname: 0 for classname in classes}\n",
        "    total_pred = {classname: 0 for classname in classes}\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data in test_loader:\n",
        "            images, labels = data\n",
        "            outputs = net(images)\n",
        "            _, predictions = torch.max(outputs, 1)\n",
        "            # собираем правильные прогнозы для каждого класса\n",
        "            for label, prediction in zip(labels, predictions):\n",
        "                if label == prediction:\n",
        "                    correct_pred[classes[label]] += 1\n",
        "                total_pred[classes[label]] += 1\n",
        "\n",
        "\n",
        "    # Выводим точность на каждом классе\n",
        "    for classname, correct_count in correct_pred.items():\n",
        "        accuracy = 100 * float(correct_count) / total_pred[classname]\n",
        "        print(f'Accuracy for class: {classname:5s} is {accuracy:.1f} %')\n",
        "\n",
        "    param_count = get_n_params(net)\n",
        "    print(f'Model size: {param_count} parametres')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a71b790",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "id": "7a71b790",
        "outputId": "7ae9e5e7-7567-448f-fd63-393582e0756c"
      },
      "outputs": [],
      "source": [
        "# dataiter = iter(test_loader)\n",
        "# images, labels = next(dataiter)\n",
        "\n",
        "# # вывод изображений\n",
        "# imshow(torchvision.utils.make_grid(images))\n",
        "# print('GroundTruth: ', ' '.join(f'{classes[labels[j]]:5s}' for j in range(2)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8651f588",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8651f588",
        "outputId": "d848b0e8-d096-4577-f716-4c81abd455e8"
      },
      "outputs": [],
      "source": [
        "# net = Net_1()\n",
        "# net.load_state_dict(torch.load(PATH))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5aee0378",
      "metadata": {
        "id": "5aee0378"
      },
      "outputs": [],
      "source": [
        "# outputs = net(images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5d73809a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5d73809a",
        "outputId": "f258e013-0553-4425-df12-a97be1bdf8a2"
      },
      "outputs": [],
      "source": [
        "# correct = 0\n",
        "# total = 0\n",
        "# # поскольку мы не обучаемся, нам не нужно вычислять градиенты для наших выходов\n",
        "# with torch.no_grad():\n",
        "#     for data in test_loader:\n",
        "#         images, labels = data\n",
        "#         # рассчитываем выходные данные, пропуская изображения через сеть\n",
        "#         outputs = net(images)\n",
        "#         # класс с наибольшей мощностью - это то, что мы выбираем в качестве предсказания\n",
        "#         _, predicted = torch.max(outputs.data, 1)\n",
        "#         total += labels.size(0)\n",
        "#         correct += (predicted == labels).sum().item()\n",
        "\n",
        "# print(f'Accuracy of the network on the {test_len} test images: {100 * correct // total} %')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0562b18b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0562b18b",
        "outputId": "01058dd0-2786-4864-d5bb-617e69232a41"
      },
      "outputs": [],
      "source": [
        "# # Подготовка\n",
        "# correct_pred = {classname: 0 for classname in classes}\n",
        "# total_pred = {classname: 0 for classname in classes}\n",
        "\n",
        "# with torch.no_grad():\n",
        "#     for data in test_loader:\n",
        "#         images, labels = data\n",
        "#         outputs = net(images)\n",
        "#         _, predictions = torch.max(outputs, 1)\n",
        "#         # собираем правильные прогнозы для каждого класса\n",
        "#         for label, prediction in zip(labels, predictions):\n",
        "#             if label == prediction:\n",
        "#                 correct_pred[classes[label]] += 1\n",
        "#             total_pred[classes[label]] += 1\n",
        "\n",
        "\n",
        "# # Выводим точность на каждом классе\n",
        "# for classname, correct_count in correct_pred.items():\n",
        "#     accuracy = 100 * float(correct_count) / total_pred[classname]\n",
        "#     print(f'Accuracy for class: {classname:5s} is {accuracy:.1f} %')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "PdfL_42_bTa8",
      "metadata": {
        "id": "PdfL_42_bTa8"
      },
      "source": [
        "# Задание на практику 2\n",
        "1. Модифицировать архитектуру СНС в примере (показать повышение точности)\n",
        "2. Обучить свой классификатор на своем датасете\n",
        "3. Назвать популярые архитектуры СНС и их особенности"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "4adb2b3a86768c0ab9c68d017220c97866613aeca6db1d74ccc533002803c558"
      }
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "006b68923f6c4ed6abf97a717eae68ab": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "13db09b7d5f24cbc82eb6bb4a7e2b04d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fe780edc9b174e5a8fb91a6272b4ecc1",
            "max": 170498071,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5b92f21e071d4887bd491b55dc3c09e4",
            "value": 170498071
          }
        },
        "29acf99c6faf488d9e6b7492ead45986": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f636d53c03440a6a47b2dafcfd8886f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5aeea86d346c49a9a070efeb746c15c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fcdd0995425442de83aedc6c157396f9",
              "IPY_MODEL_13db09b7d5f24cbc82eb6bb4a7e2b04d",
              "IPY_MODEL_eda4571c6119464896cda99e85841e46"
            ],
            "layout": "IPY_MODEL_cf94e662f9114e6eac24ccc6b671efad"
          }
        },
        "5b92f21e071d4887bd491b55dc3c09e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c967b526ebda48fb98be888e61843fc9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cf94e662f9114e6eac24ccc6b671efad": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eda4571c6119464896cda99e85841e46": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_006b68923f6c4ed6abf97a717eae68ab",
            "placeholder": "​",
            "style": "IPY_MODEL_c967b526ebda48fb98be888e61843fc9",
            "value": " 170498071/170498071 [00:52&lt;00:00, 1959295.28it/s]"
          }
        },
        "fcdd0995425442de83aedc6c157396f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_29acf99c6faf488d9e6b7492ead45986",
            "placeholder": "​",
            "style": "IPY_MODEL_2f636d53c03440a6a47b2dafcfd8886f",
            "value": "100%"
          }
        },
        "fe780edc9b174e5a8fb91a6272b4ecc1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
